{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "985989a6-a2fd-4902-90d1-488f0d66eef0",
   "metadata": {},
   "source": [
    "## Линейная модель\n",
    "\n",
    "Линейная модель - это математическая модель, используемая в машинном обучении для предсказания значений на основе линейной комбинации входных признаков. Она предполагает, что выходное значение (прогноз) можно выразить как взвешенную сумму входных признаков с добавлением смещения (bias). Математически это можно записать следующим образом:\n",
    "\n",
    "\n",
    "$\\hat{y} = w_1x_1 + w_2x_2 + \\ldots + w_nx_n + b$\n",
    "\n",
    "где:\n",
    "- $\\hat{y}$ - прогнозируемое значение,\n",
    "- $w_1, w_2, \\ldots, w_n$ - веса (параметры) модели для каждого признака,\n",
    "- $x_1, x_2, \\ldots, x_n$ - входные признаки,\n",
    "- $b$ - смещение (bias).\n",
    "\n",
    "### Вычисление выхода линейной модели\n",
    "\n",
    "Для вычисления выхода линейной модели, просто подставьте значения признаков в уравнение, используя соответствующие веса и смещение. Матричная формула для вычисления выхода линейной модели для набора данных \\(X\\) выглядит следующим образом:\n",
    "\n",
    "$\\hat{Y} = X \\cdot \\mathbf{w} + b$\n",
    "\n",
    "где:\n",
    "- $\\hat{Y}$ - вектор прогнозов для всего набора данных,\n",
    "- $X$ - матрица признаков, где каждая строка представляет один образец, а столбцы - признаки,\n",
    "- $\\mathbf{w}$ - вектор весов модели,\n",
    "- $b$ - смещение (bias).\n",
    "\n",
    "### Обучение линейной модели\n",
    "\n",
    "Обучение линейной модели заключается в настройке параметров (весов и смещения) так, чтобы они наилучшим образом соответствовали обучающим данным. Одним из наиболее распространенных методов обучения линейной модели является градиентный спуск.\n",
    "\n",
    "### Градиентный спуск\n",
    "\n",
    "Градиентный спуск - это метод оптимизации, используемый для обновления параметров модели с целью минимизации функции потерь. Функция потерь оценивает, насколько хорошо модель предсказывает реальные значения на обучающих данных.\n",
    "\n",
    "Для линейной регрессии, часто используется среднеквадратичная ошибка (Mean Squared Error - MSE) в качестве функции потерь:\n",
    "\n",
    "$MSE = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2$\n",
    "\n",
    "где:\n",
    "- $N$ - количество обучающих примеров,\n",
    "- $y_i$ - реальное значение для i-го примера,\n",
    "- $\\hat{y}_i$ - прогнозированное значение для i-го примера.\n",
    "\n",
    "### Корректировка весов модели\n",
    "\n",
    "Для обновления весов модели в методе градиентного спуска, используется градиент функции потерь по отношению к параметрам модели. Градиент показывает направление наибольшего увеличения функции потерь, поэтому мы двигаемся в противоположном направлении градиента, чтобы уменьшить потери. Формула для обновления весов выглядит следующим образом:\n",
    "\n",
    "$\\mathbf{w}_{\\text{новые}} = \\mathbf{w}_{\\text{старые}} - \\text{learning_rate} \\cdot \\nabla L$\n",
    "\n",
    "где:\n",
    "- $\\mathbf{w}_{\\text{новые}}$ - новые веса после обновления,\n",
    "- $\\mathbf{w}_{\\text{старые}}$ - текущие веса,\n",
    "- $\\text{learning_rate}$ - скорость обучения (коэффициент, контролирующий размер шага градиентного спуска),\n",
    "- $\\nabla L$ - градиент функции потерь по параметрам модели.\n",
    "\n",
    "Этот процесс повторяется до достижения сходимости или определенного числа итераций.\n",
    "\n",
    "## Классификатор на линейной модели\n",
    "\n",
    "На линейной модели можно построить и классификатор. Для этого нужно выход линейной модели отбразить в интервал от 0 до 1. В этом нам поможет логистическая функция:\n",
    "\n",
    "$\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "Для обучения скорректируем функцию потерь. Нетрудно показать, что функция, называемая кросс-энтропией на самом деле соответствует максимизации правдоподобия (кстати, почитайте про правдоподобие), ниже представлено выражение для нее\n",
    "\n",
    "$BCE = -\\frac{1}{N} \\sum_{i=1}^{N} \\left(y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)\\right)$\n",
    "\n",
    "где:\n",
    "- $N$ - количество обучающих примеров,\n",
    "- $y_i$ - истинная метка класса (0 или 1) для i-го примера,\n",
    "- $\\hat{y}_i$ - вероятность принадлежности к классу 1 для i-го примера (выход сигмоидной функции).\n",
    "\n",
    "Будем считать, что модель относит объект к 1 классу, если ее выход $>=0.5$, иначе - 0 класс.\n",
    "\n",
    "## Как считать градиенты\n",
    "\n",
    "Приведу градиент для кросс-энтропии:\n",
    "\n",
    "$\\nabla_{\\mathbf{w}} \\text{BCE} = -\\frac{1}{N} \\mathbf{X}^T (\\mathbf{y} - \\hat{\\mathbf{y}})$\n",
    "\n",
    "Для MSE вычислить градиент самостоятельно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a04ef46-22ed-49ba-a1d0-da06c40829b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLinearModel\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class LinearModel:\n",
    "    def __init__(self, num_features):\n",
    "        self.num_features = num_features\n",
    "        self.weights = np.random.randn(num_features)\n",
    "        self.bias = 0.0\n",
    "\n",
    "    def call(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "\n",
    "class LinearRegressor(LinearModel):\n",
    "    def fit(self, X, y, learning_rate=0.01, epochs=100):\n",
    "        error_history = []\n",
    "        for _ in range(epochs):\n",
    "            predictions = self.call(X)\n",
    "            error = y - predictions\n",
    "            gradient = -np.dot(X.T, error) / len(y)\n",
    "            self.weights -= learning_rate * gradient\n",
    "            self.bias -= learning_rate * np.mean(error)\n",
    "            current_error = ((y - predictions) ** 2).sum()\n",
    "            error_history.append(current_error)\n",
    "        return error_history\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.call(X)\n",
    "\n",
    "\n",
    "class LinearClassifier(LinearModel):\n",
    "    def fit(self, X, y, learning_rate=0.01, epochs=100):\n",
    "        error_history = []\n",
    "        for _ in range(epochs):\n",
    "            predictions = self.call(X)\n",
    "            sigmoid = 1 / (1 + np.exp(-predictions))\n",
    "            error = y - sigmoid\n",
    "            gradient = -np.dot(X.T, error) / len(y)\n",
    "            self.weights -= learning_rate * gradient\n",
    "            self.bias -= learning_rate * np.mean(error)\n",
    "            current_error = -np.mean(y * np.log(sigmoid) + (1 - y) * np.log(1 - sigmoid))\n",
    "            error_history.append(current_error)\n",
    "        return error_history\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = self.call(X)\n",
    "        sigmoid = 1 / (1 + np.exp(-predictions))\n",
    "        return np.round(sigmoid)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        predictions = self.call(X)\n",
    "        sigmoid = 1 / (1 + np.exp(-predictions))\n",
    "        return sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0bb8fc-ec29-4cd7-a693-ac77b0a46cff",
   "metadata": {},
   "source": [
    "## Проверьте модели на данных\n",
    "\n",
    "### Линейная модель\n",
    "\n",
    "#### Description:\n",
    "The Student Performance Dataset is a dataset designed to examine the factors influencing academic student performance. The dataset consists of 10,000 student records, with each record containing information about various predictors and a performance index.\n",
    "\n",
    "#### Variables:\n",
    "- Hours Studied: The total number of hours spent studying by each student.\n",
    "- Previous Scores: The scores obtained by students in previous tests.\n",
    "- Extracurricular Activities: Whether the student participates in extracurricular activities (Yes or No).\n",
    "- Sleep Hours: The average number of hours of sleep the student had per day.\n",
    "- Sample Question Papers Practiced: The number of sample question papers the student practiced.\n",
    "\n",
    "#### Target Variable:\n",
    "\n",
    "- Performance Index: A measure of the overall performance of each student. The performance index represents the student's academic performance and has been rounded to the nearest integer. The index ranges from 10 to 100, with higher values indicating better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47687e94-a2d2-4c25-8d48-54d13d621fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d71d4-ceeb-4611-8a43-7012308a19e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/aanuu/OneDrive/Документы/уник/5_семестр/пр/lab3-main (1)/lab3-main/Student_Performance.csv\")\n",
    "\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "# Определение целевой переменной Y\n",
    "\n",
    "Y = data['Performance Index']\n",
    "\n",
    "# Определение признаков X\n",
    "X = data[['Hours Studied','Previous Scores','Extracurricular Activities','Sleep Hours','Sample Question Papers Practiced','Performance Index'\n",
    "]].copy()\n",
    "\n",
    "# Преобразование категориальной переменной с использованием pd.Categorical\n",
    "X['Extracurricular Activities'] = pd.Categorical(X['Extracurricular Activities'], categories=['No', 'Yes']).codes\n",
    "\n",
    "# Преобразование X в numpy-массив\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a2ec08-17d8-4e11-9f20-b2ccd9a9f760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Вычислите среднее по столбцам.\n",
    "mean = np.mean(X, axis=0)\n",
    "\n",
    "# Вычислите стандартное отклонение по столбцам.\n",
    "std = np.std(X, axis=0)\n",
    "\n",
    "# Нормализуйте данные по столбцам (стандартное масштабирование).\n",
    "normalized_X = (X - mean) / std\n",
    "\n",
    "# Нормализуйте и выходные данные\n",
    "normalized_Y = (Y.to_numpy() - np.mean(Y.to_numpy())) / np.std(Y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c8fdd2-2f45-4765-900a-a0d949c8d96f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = LinearRegressor(num_features=X.shape[1])\n",
    "history = lr.fit(normalized_X, normalized_Y, learning_rate=0.01, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2b9d0-6210-4107-8c47-1893ded1cdb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(history) + 1)\n",
    "\n",
    "# Постройте график обучения.\n",
    "plt.plot(epochs, history, 'b', label='MSE')\n",
    "plt.title('График обучения')\n",
    "plt.xlabel('Эпохи')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "\n",
    "# Отобразите график.\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e91f08e-3089-4464-9763-27fef0a1a74a",
   "metadata": {},
   "source": [
    "### Классификатор\n",
    "#### Context\n",
    "When a bank receives a loan application, based on the applicant’s profile the bank has to make a decision regarding whether to go ahead with the loan approval or not. Two types of risks are associated with the bank’s decision.\"\n",
    "\n",
    "\"If the applicant is a good credit risk, i.e. is likely to repay the loan, then not approving the loan to the person results in a loss of business to the bank\n",
    "If the applicant is a bad credit risk, i.e. is not likely to repay the loan, then approving the loan to the person results in a financial loss to the bank.\"\n",
    "\n",
    "The predictors that may potentially have any influence on Creditability:\n",
    "\n",
    "Account Balance: No account (1), None (No balance) (2), Some Balance (3)\n",
    "\n",
    "Payment Status: Some Problems (1), Paid Up (2), No Problems (in this bank) (3)\n",
    "\n",
    "Savings/Stock Value: None, Below 100 DM, [100, 1000] DM, Above 1000 DM\n",
    "\n",
    "Employment Length: Below 1 year (including unemployed), [1, 4), [4, 7), Above 7\n",
    "\n",
    "Sex/Marital Status: Male Divorced/Single, Male Married/Widowed, Female\n",
    "\n",
    "No of Credits at this bank: 1, More than 1\n",
    "\n",
    "Guarantor: None, Yes\n",
    "\n",
    "Concurrent Credits: Other Banks or Dept Stores, None\n",
    "\n",
    "ForeignWorker variable may be dropped from the study\n",
    "\n",
    "Purpose of Credit: New car, Used car, Home Related, Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd3871-36fb-4cf4-8178-7f8e267909a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/aanuu/OneDrive/Документы/уник/5_семестр/пр/lab3-main (1)/lab3-main/german.csvprint(data.head())\", sep=';')\n",
    "print(data.head())\n",
    "\n",
    "print(data.head())\n",
    "Y = data['Creditability'] \n",
    "X = data.drop('Creditability', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5185da-6c3a-4a4e-aece-10f028d70695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data.describe())print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc712a-7d9b-4121-af7a-f5107b5d95b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Вычислите среднее по столбцам.\n",
    "mean = np.mean(X, axis=0)\n",
    "\n",
    "# Вычислите стандартное отклонение по столбцам.\n",
    "std = np.std(X, axis=0)\n",
    "\n",
    "# Нормализуйте данные по столбцам (стандартное масштабирование).\n",
    "normalized_X = (X - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c38a96-4e7d-46f1-8d11-031e3c6e7924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Создание объекта классификатора\n",
    "lc = LinearClassifier(num_features=X.shape[1])\n",
    "# Обучение модели\n",
    "history = lc.fit(normalized_X, Y.to_numpy(), learning_rate=0.01, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764abb9b-2fc3-4859-be34-06099840a914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = lc.predict(normalized_X)\n",
    "print('accuracy: ', (pred == Y).sum() / len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb2e181-a6c8-429d-bd55-2d8645c193a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = lc.predict(normalized_X)\n",
    "print('accuracy: ', (pred == Y).sum() / len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee311e77-efda-4f2f-bd13-308822206894",
   "metadata": {},
   "source": [
    "Вычислите для этой модели ROC-AUC, precision, recall и f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
